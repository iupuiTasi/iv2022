
<!DOCTYPE html><!-- This site was created in Webflow. http://www.webflow.com --><!-- Last Published: Fri May 27 2022 18:53:50 GMT+0000 (Coordinated Universal Time) --><html data-wf-domain="bobs-initial-project-4306d2.webflow.io" data-wf-page="613787b27794b033ef9f1329" data-wf-site="613787b27794b085129f1328"><head><meta charset="utf-8"/><title>IV22</title><meta content="width=device-width, initial-scale=1" name="viewport"/><meta content="Webflow" name="generator"/><link href="https://uploads-ssl.webflow.com/613787b27794b085129f1328/css/bobs-initial-project-4306d2.webflow.e69ff117b.css" rel="stylesheet" type="text/css"/><!--[if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif]--><script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script></head><body><div data-collapse="medium" data-animation="default" data-duration="400" data-easing="ease" data-easing2="ease" role="banner" class="navbar w-nav"><div class="w-container"><nav role="navigation" class="w-nav-menu"><a href="#About" class="w-nav-link">About</a><a href="#topics" class="w-nav-link">Topics</a><a href="#agenda" class="w-nav-link">Schedule</a><a href="#Speakers" class="w-nav-link">Speakers</a></nav><div class="w-nav-button"><div class="w-icon-nav-menu"></div></div><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/621ceaa315fde5d726494b2d_Screen%20Shot%202022-02-25%20at%209.12.49%20AM.png" loading="lazy" width="185" alt=""/></div></div><header id="hero-overlay" class="hero-overlay wf-section"><div class="centered-container w-container"><h1>2nd Workshop On The Prediction Of Pedestrian Behaviors For Automated Driving</h1><h2>At IV 2022</h2><h3>June 5th, 2022 – Aachen, German</h3></div></header><div class="wf-section"><div class="w-container"><h1 class="heading-15">Important Information</h1><ul role="list" class="list-11"><li class="list-item-21">Deadline for workshop paper submission: <strong>March 8th, 2022</strong></li><li class="list-item-22">Acception/Rejection Notification: <strong>April 22nd, 2022</strong></li><li class="list-item-23">Final paper submission: <strong>May 1st, 2022</strong></li><li class="list-item-23">Workshop is hosted in person and remotely<br/></li><li class="list-item-23"><strong>Workshop Registration: </strong><a href="https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fiv2022.com%2Fparticipant-registration&amp;data=05%7C01%7Ctspisak%40iu.edu%7C8426785c1ad943533c5108da3ff860ec%7C1113be34aed14d00ab4bcdd02510be91%7C0%7C0%7C637892633246368240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=C9J7kIkQs69y8VeeggVjAIcBIHcAH5fGbYbfKf3nFIw%3D&amp;reserved=0" target="_blank">https://iv2022.com/participant-registration</a><br/></li><li class="list-item-23"><strong>Location: Workshop is planned in conference Room K9 in Eurogress:<br/></strong><a href="https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.eurogress-aachen.de%2Fen%2Feurogress-aachen%2Fconference-room-9&amp;data=05%7C01%7Ctspisak%40iu.edu%7C8426785c1ad943533c5108da3ff860ec%7C1113be34aed14d00ab4bcdd02510be91%7C0%7C0%7C637892633246368240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=RnKk33042o4JX5JsnaPlNmElvqzPJ7NOkrhFyJ1JQns%3D&amp;reserved=0" target="_blank"><strong>https://www.eurogress-aachen.de/en/eurogress-aachen/conference-room-9</strong></a><strong> </strong><br/></li></ul><ul role="list" class="list-7"></ul></div></div><div class="section-3 wf-section"><div class="w-container"><h1 id="About" class="heading-8">About</h1><p class="paragraph-12">With the progress of automated driving technologies, self-driving cars are driving safely on highways and freeways in most circumstances. However, the lack of safe and smooth interactions with pedestrians becomes one of the significant obstacles preventing fully autonomous vehicles in city streets. Protections of vulnerable road users like pedestrians are of the highest priority in traffic safety, and crashes with pedestrians will significantly impact the trust and public attitudes towards the new mobility technology. Disruptive interactions with pedestrians may also lower both the riding experiences and driving efficiency in the pedestrian-rich road environments. It is vital to understand pedestrians and make motion planning based on the predictions of their behaviors.<br/> <br/>Besides pedestrian detection and tracking, many research efforts have been put into recognizing pedestrians&#x27; behaviors and predicting their trajectories in the past few years. The achievements can predict potential crashes and make motion-planning decisions accordingly in a longer duration. This Workshop will focus on the detection, recognition, and prediction of pedestrian behaviors for automated driving cars to interact with them smoothly. The goal is to build a platform for sharing state-of-the-art models, algorithms, and datasets in the field and identifying research needs and directions.</p></div></div><div class="section-4 wf-section"><div class="container-7 w-container"><h1 id="topics" class="topics">Topics</h1><ul role="list" class="list-10"><li class="list-item-19">Vehicle-pedestrian interaction</li><li class="list-item-18">Pedestrian detection and tracking</li><li class="list-item-20">Pedestrian trajectory prediction</li><li class="list-item-20">Pedestrian intention estimation</li><li class="list-item-20">Pedestrian behavior and action recognition</li><li class="list-item-20">Pedestrian behavior modeling</li><li class="list-item-20">Factors affecting pedestrian behavior and decision-making</li><li class="list-item-20">Vehicle motion and path planning</li><li class="list-item-20">Performance evaluation for pedestrian behavior prediction algorithms</li></ul></div><div class="container-2 w-container"></div><div class="w-container"><h1 id="agenda" class="heading-16">Tentative Agenda</h1><div class="w-layout-grid grid"><h3 id="w-node-_641f6e3e-f0a9-ba98-e4bf-01c2361cc317-ef9f1329" class="heading-19">Speaker</h3><h3 id="w-node-ce0081fb-7800-13b6-96e2-202638ebf44f-ef9f1329" class="heading-21">Abstract</h3><h3 id="w-node-_214938e1-0b45-866d-7a99-2af83ceaee08-ef9f1329" class="heading-20">Title</h3><div id="w-node-_0e241cad-9ed9-cd12-1b05-00894ef21758-ef9f1329">1:00 pm</div><div id="w-node-ca4bf0f1-317f-a6c4-ec4c-773ebc943ac2-ef9f1329">Renran Tian(In Person)</div><div id="w-node-_8d510ca9-c4bc-6d5a-980e-1add41cc69fb-ef9f1329">Introduction</div><div id="w-node-f3d667c5-2e2e-4f63-f43c-be2867584a62-ef9f1329">A brief introduction to the workshop.</div><h3 id="w-node-_73e05940-78ca-c3a7-107a-8b439ed3cfd4-ef9f1329" class="heading-18">Time</h3></div><h4 class="heading-17">Section 1: Invited Talks</h4><div class="w-layout-grid grid"><div id="w-node-_1a31642b-5bfc-dddd-7125-0558070c5b8b-ef9f1329"><a href="#Mohan">Mohan Trived</a>i / Ross Greer <br/>(In Person/Remote)</div><div id="w-node-_0bc4a03c-ab27-e306-ac6c-888ab53d2f7a-ef9f1329">From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and Analysis on Diverse Datasets</div><div id="w-node-bcc7b104-c6e2-0282-2d83-e851a87e9840-ef9f1329">1:40 pm</div><div id="w-node-bcc7b104-c6e2-0282-2d83-e851a87e9842-ef9f1329"><a href="#Amir">Amir Rasouli </a>/ Iuliia Kotseruba (In Person)</div><div id="w-node-bcc7b104-c6e2-0282-2d83-e851a87e9844-ef9f1329">Intend-Wait-Cross: Towards Modeling Realistic Pedestrian Crossing Behavior</div><div id="w-node-bcc7b104-c6e2-0282-2d83-e851a87e9846-ef9f1329">In this paper, we present a microscopic agent-based pedestrian behavior model Intend-Wait-Cross. The model is comprised of rules representing behaviors of pedestrians as a series of decisions that depend on their individual characteristics (e.g. demographics, walking speed, law obedience) and environmental conditions (e.g. traffic flow, road structure). The model’s main focus is on generating realistic crossing decision model, which incorporates an improved formulation of time-to-collision (TTC) computation accounting for context, vehicle dynamics, and perceptual noise.<br/><br/> Our model generates a diverse population of agents acting in a highly configurable environment. All model components, including individual characteristics of pedestrians, types of decisions they make, and environmental factors, are motivated by studies on pedestrian traffic behavior. Model parameters are calibrated using a combination of naturalistic driving data and estimates from the literature to maximize the realism of the simulated behaviors. A number of experiments validate various aspects of the model, such as pedestrian crossing patterns, and individual characteristics of pedestrians.</div><div id="w-node-_602739a1-2e12-7d24-78fb-39539b0fa3fd-ef9f1329">2:10 pm</div><div id="w-node-cab2c608-7bc8-78ed-0f1f-b576f1325cd0-ef9f1329">In our work, we contribute an EM algorithm for estimation of corner points and linear crossing segments for both marked and unmarked pedestrian crosswalks using the detections of pedestrians from processed LiDAR point clouds. We demonstrate the algorithmic performance by analyzing two real-world datasets containing multiple periods of data collection for a four-corner and two-corner intersection. Additionally, we include a Python video tool to visualize the crossing parameter estimation, pedestrian trajectories, and phase intervals in our public source code.</div><div id="w-node-_93d65b01-c18d-fe65-a1de-17baba68dddc-ef9f1329">Golam Md Muktadir/ Jim Whitehead<br/> (In Person/Remote)</div><div id="w-node-_8b79cece-75ea-37ab-8d7c-885a1e80b13b-ef9f1329">Adversarial jaywalker modeling for simulation-based testing of Autonomous Vehicle Systems</div><div id="w-node-d92513b4-f93a-ab53-9802-5730f7f8a301-ef9f1329" class="text-block-8">We present an approach for creating adversarial jaywalkers, autonomous pedestrian models which intentionally act to create unsafe situations involving other vehicles. An adversarial jaywalker employs a hybrid state-model with social forces and state transition rules. The parameters (for social forces and state transitions) of this model are tuned via reinforcement learning to create risky situations faster with synthetic yet plausible behavior. The resulting jaywalkers are capable of realistic behavior while still engaging in sufficiently risky actions to be useful for testing. These adversarial pedestrian models are useful in a wide range of scenario-based tests for autonomous vehicles</div><div id="w-node-_8d41a0ba-a672-ace4-d91c-fcc5dc0e47df-ef9f1329">2:40 pm</div><div id="w-node-aa21ac61-b586-5eb6-280b-813796c39f8b-ef9f1329"><a href="#Josh">Josh Domeyer</a> (Remote)</div><div id="w-node-_6988a69e-4a91-5ab2-0b7b-94092288f8c6-ef9f1329">TBD</div><div id="w-node-_13a7ba20-6235-34a0-7f69-f7d49c29f967-ef9f1329">TBD</div><div id="w-node-_990d889a-68ab-c6b1-1d7a-6b0448e06ba0-ef9f1329">1:10 pm </div></div><h4 class="heading-17">10-minute Break</h4><div class="w-layout-grid grid"><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9faa5-ef9f1329"><a href="#Tian">Renran Tian</a> (In Person)</div><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9faa9-ef9f1329">PSI: A Pedestrian Behavior Dataset for Socially Intelligent Autonomous Car</div><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9faab-ef9f1329">4:00 pm</div><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9faad-ef9f1329"><a href="#Ding">Zhengming Ding</a> (Remote)</div><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9faaf-ef9f1329">Interpretable Pedestrian Intent Prediction</div><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9fab1-ef9f1329">Autonomous driving attracts lots of interest in interpretable pedestrian intent models with a desirable capability that mimic human cognition. Such reasoning enables forecasting of the next actions in pedestrian videos. In recent years, various models have been developed based on convolution operations for prediction or forecasting, with exploring the spatiotemporal relationships or mining implicit visual cues. In this talk, we present to discuss the motivation of interpretation, and review several existing proposed model, with further presenting the challenges for autonomous driving. To evaluate the AI models, we proposes and shares another benchmark dataset called the IUPUI-CSRC Pedestrian Situated Intent (PSI) data with two innovative labels besides comprehensive computer vision labels. The first novel label is the dynamic intent changes for the pedestrians to cross in front of the ego-vehicle, achieved from 24 drivers with diverse backgrounds. The second one is the text-based explanations of the driver reasoning process when estimating pedestrian intents and predicting their behaviors during the interaction period.</div><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9fab8-ef9f1329">Prediction of pedestrian behavior is critical for fully autonomous vehicles to drive in busy city streets safely and efficiently. The future autonomous cars need to fit into mixed conditions with not only technical but also social capabilities. As more algorithms and datasets have been developed to predict pedestrian behaviors, these efforts lack the benchmark labels and the capability to estimate the temporal-dynamic intent changes of the pedestrians, provide explanations of the interaction scenes, and support algorithms with social intelligence. This paper proposes and shares another benchmark dataset called the IUPUI-CSRC Pedestrian Situated Intent (PSI) data with two innovative labels besides comprehensive computer vision labels. The first novel label is the dynamic intent changes for the pedestrians to cross in front of the ego-vehicle, achieved from 24 drivers with diverse backgrounds. The second one is the text-based explanations of the driver reasoning process when estimating pedestrian intents and predicting their behaviors during the interaction period. These innovative labels can enable several computer vision tasks, including pedestrian intent/behavior prediction, vehicle-pedestrian interaction segmentation, and video-to-language mapping for explainable algorithms. The released dataset can fundamentally improve the development of pedestrian behavior prediction models and develop socially intelligent autonomous cars to interact with pedestrians efficiently. The dataset has been evaluated with different tasks and is released to the public to access.</div><div id="w-node-bd89302a-5b5e-2078-62b0-c4a491c9faca-ef9f1329">3:30 pm </div></div><h4 class="heading-17">Section II: Discussions</h4><div class="w-layout-grid grid"><div id="w-node-bed292a6-0393-a7a2-41b2-b6b75217d25e-ef9f1329">All the participants</div><div id="w-node-bed292a6-0393-a7a2-41b2-b6b75217d262-ef9f1329">5:00 pm</div><div id="w-node-bed292a6-0393-a7a2-41b2-b6b75217d264-ef9f1329" class="text-block-9">Wrap Up</div><div id="w-node-bed292a6-0393-a7a2-41b2-b6b75217d26c-ef9f1329">4:30 pm </div></div></div></div><section id="feature-section" class="feature-section wf-section"><div class="w-container"><h1 id="Speakers" class="heading-11">Speakers</h1><h3 class="heading-13">Invited Speaker</h3></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cefc5710a976e5b68131b_Mohan%20Trivedi.png" sizes="(max-width: 479px) 82vw, (max-width: 767px) 85vw, 100vw" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cefc5710a976e5b68131b_Mohan%20Trivedi-p-500.png 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cefc5710a976e5b68131b_Mohan%20Trivedi.png 512w" alt="" class="feature-image"/></div><div><h2 id="Mohan" class="heading-9">Mohan Trivedi</h2><h5>University of California – San Diego</h5><a href="https://jacobsschool.ucsd.edu/node/3464">Website</a><p class="paragraph-7"><strong>Short bio: </strong>Mohan Trivedi received his PhD in Electrical Engineering from Utah State University in 1979, after completing undergraduate work in India. He has published extensively and has edited over a dozen volumes including books, special issues, video presentations, and conference proceedings. Trivedi is a recipient of the Pioneer Award and the Meritorious Service Award from the IEEE ComputerSociety; and the Distinguished Alumnus Award from Utah State University. He isa Fellow of the International Society for Optical Engineering (SPIE). He is a founding member of the Executive Committee of the UC System-wide Digital MediaInnovation Program (DiMI). Trivedi is also Editor-in-Chief of Machine Vision&amp; Applications (http://link.springer-ny.com/link/service/journals/00138/index.htm).</p></div></div><div class="w-container"><h3 class="heading-14">Workshop Organizers</h3></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1.jpg" sizes="(max-width: 479px) 96vw, (max-width: 767px) 85vw, 100vw" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1-p-800.jpeg 800w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1.jpg 914w" alt="" class="feature-image"/></div><div><h2 id="Josh" class="heading-9">Josh Domeyer</h2><h5>Toyota Motor North America</h5><a href="https://scholar.google.com/citations?hl=en&amp;user=z3zEcpUAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Website</a><p class="paragraph-7"><strong>Short bio: </strong>Josh Domeyer is a senior researcher in the Toyota Collaborative Safety Research Center. He received a Ph.D. in Industrial and Systems Engineering at the University of Wisconsin-Madison in 2021 and B.S. and M.S. degrees in Experimental Psychology from Central Michigan University in 2009 and 2011. He has been a human factors researcher at Toyota since 2011 where his research has focused on driver-vehicle interface, distraction, and human-automation interaction. He joined the Collaborative Safety Research Center in 2017 to explore the communication between drivers and pedestrians with the goal of informing the development of vehicle automation. He is the Chair of SAE’s Safety and Human Factors Steering Committee and a U.S. expert for the ISO TC22/SC39/WG8 standards group.</p></div></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b70d44d7c30bcccc7f1ae_Screen%20Shot%202021-09-10%20at%209.50.33%20AM.png" sizes="(max-width: 479px) 82vw, (max-width: 767px) 85vw, 100vw" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b70d44d7c30bcccc7f1ae_Screen%20Shot%202021-09-10%20at%209.50.33%20AM-p-500.png 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b70d44d7c30bcccc7f1ae_Screen%20Shot%202021-09-10%20at%209.50.33%20AM.png 732w" alt="" class="feature-image"/></div><div><h2 id="Amir" class="heading-9">Amir Rasouli</h2><h5>Huawei Technologies Canada</h5><a href="https://aras62.github.io/">Website</a><p class="paragraph-8"><strong>Short bio: </strong>Amir Rasouli is a senior research scientist leading the behavior prediction team atNoah’s Ark Laboratory, Huawei, Canada. He received B.Eng. degree in computer systems engineering and B.A. in Business Management from the Royal MelbourneInstitute of Technology. He obtained M.A.Sc. degree in computer engineering under the supervision of Prof. John Tsotsos at York University studying the role of attention in active visual object search for mobile robots. He completed his Ph.D. degree in the same lab on the topic of pedestrian behavior understanding and prediction in the context of autonomous driving. His current work focuses on various aspects of road user behavior prediction including analysis of naturalistic driving data, understanding theoretical foundations of interactions between heterogeneous traffic participants, modeling vehicle and pedestrian behavior, simulation, and development of predictive models for intelligent driving systems.</p></div></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cf18cf59a46cbdd9d4b02_Ding.png" sizes="(max-width: 479px) 100vw, (max-width: 767px) 85vw, 100vw" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cf18cf59a46cbdd9d4b02_Ding-p-500.png 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cf18cf59a46cbdd9d4b02_Ding-p-800.png 800w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cf18cf59a46cbdd9d4b02_Ding-p-1080.png 1080w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/621cf18cf59a46cbdd9d4b02_Ding.png 1100w" alt="" class="feature-image"/></div><div><h2 id="Ding" class="heading-9">Zhengming (Allan) Ding</h2><h5>Tulane University</h5><a href="http://www.cs.tulane.edu/~zding1/">Website</a><p class="paragraph-9"><strong>Short bio: </strong>Dr.Ding is a Tenure-Track Assistant Professor at the Department of ComputerScience, Tulane University.  He is an active researcher in the fields of face recognition, transfer learning, multi-view learning, and has published over 50 articles in the flagship conferences/journals and books. He serves as Associate Editor of IET ImageProcessing, and Journal of Electronic Imaging. He also serves many leading conferences/workshops in the vision and data mining fields, e.g., the Publicity Chair of AMFG2017, program co-chair of IEEE Big Data Workshop 2017, and workshop Chairs ofAMFG 2021.He organizes four tutorials on multi-view learning in the FG 2017, CVPR 2018,IEEE BigData 2018, AAAI 2019 and IJCAI 2020. He also serves as senior program committee for AAAI 2019/2020, IJCAI 2021, and program committee for CVPR2018-2021, FG 2017-2019, and reviewers of many prestigious journals includingIEEE TPAMI, TNNLS, TKDE, TIP, TMM.</p></div></div><div class="container-5 w-container"></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137a8e766e8e4223e9a0d62_Screen%20Shot%202021-09-06%20at%2010.32.55%20PM.png" alt="" class="feature-image"/></div><div><h2 id="Tian">Renran Tian</h2><h5>Indiana University Purdue University Indianapolis</h5><a href="https://et.iupui.edu/people/rtian">Website</a><p class="paragraph-11"><strong>Short bio: </strong>Dr. Renran Tian is an assistant professor in the Department of Computer Information &amp; Graphics Technology and the Transportation &amp; Autonomous Systems Institute (TASI) at Indiana University-Purdue University Indianapolis (IUPUI). He received his Ph.D. degree from the School of Industrial Engineering at Purdue University –West Lafayette in 2013, and B.S. and M.S. in Mechanical <br/>Engineering from Tsinghua University – Beijing, China in 2002 and 2005. His research interests include human-centered computing, cognitive ergonomic, computational behavior analysis, human-AI interaction, and autonomous driving. He serves as the co-chair for Technical Activities Committee on Human Factors in Intelligent Transportation Systems (HFITS), IEEE Intelligent Transportation Systems Society.</p></div></div></section><footer id="footer" class="footer wf-section"><div class="w-container"><div class="footer-flex-container"><div class="text-block-2">For information, please contact <a href="mailto:rtian@iupui.edu" target="_blank">rtian@iupui.edu</a>.<br/></div><a href="#" class="footer-logo-link"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137a4b216a9ecb99f874d0c_Screen%20Shot%202021-09-07%20at%2012.42.50%20PM.png" alt="" class="footer-image"/></a></div></div></footer><script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=613787b27794b085129f1328" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script><script src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/js/webflow.2a0fff34d.js" type="text/javascript"></script><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]--></body></html>
