
<!DOCTYPE html><html data-wf-domain="bobs-initial-project-4306d2.webflow.io" data-wf-page="613787b27794b033ef9f1329" data-wf-site="613787b27794b085129f1328" data-wf-status="1"><head><meta charset="utf-8"/><title>IEEE ITSC Workshop</title><meta content="width=device-width, initial-scale=1" name="viewport"/><meta content="Webflow" name="generator"/><link href="https://uploads-ssl.webflow.com/613787b27794b085129f1328/css/bobs-initial-project-4306d2.webflow.6d091334c.css" rel="stylesheet" type="text/css"/><!--[if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif]--><script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script></head><body><header id="hero-overlay" class="hero-overlay wf-section"><div class="centered-container w-container"><h1>Workshop on the Detection, Recognition, and Prediction of Pedestrian Behaviors</h1><h2>In ITSC 2021</h2></div></header><div class="wf-section"><div data-collapse="medium" data-animation="default" data-duration="400" data-easing="ease" data-easing2="ease" role="banner" class="navbar w-nav"><div class="w-container"><nav role="navigation" class="w-nav-menu"><a href="#About" class="w-nav-link">About</a><a href="#topics" class="w-nav-link">Topics</a><a href="#Speakers" class="w-nav-link">Speakers</a></nav><div class="w-nav-button"><div class="w-icon-nav-menu"></div></div></div></div></div><div class="wf-section"><div class="w-container"><ul role="list" class="list-7"><li class="list-item-10"><strong class="bold-text-3"> September 19th, 2021 on Zoom</strong></li><li class="list-item-11"><strong class="bold-text-2"> 13:00 to 16:00 Eastern Time</strong></li></ul><a href="https://2021.ieee-itsc.org/registration/" class="link"><strong class="bold-text">Registration through the ITSC conference to attend</strong></a></div></div><div class="section-3 wf-section"><h1 id="About" class="heading-8">About</h1><div class="w-container"><p class="paragraph-12">With the progress of automated driving technologies, self-driving cars are already running safely on highways and freeways. However, besides other limitations, the lack of safe and smooth interactions with pedestrians becomes significant obstacles preventing fully autonomous vehicles in city streets. Protections of vulnerable road users like pedestrians are always of the highest priority in traffic safety, and crashes with pedestrians will significantly impact the trust and public attitudes towards the new mobility technology. Disruptive interactions with pedestrians may also lower both the riding experiences and moving efficiency in the pedestrian-rich road environments. With these issues, it is vital to equip autonomous vehicles with the capabilities to understand pedestrians and make motion planning based on the predictions of their behaviors. <br/><br/>Learning-based pedestrian detection and tracking algorithms have achieved significant improvements in the past several years, allowing vehicle perception systems to accurately calculate pedestrians&#x27; motions through sensor-fusion, predict potential crashes, and make motion-planning decisions accordingly. However, these safety-oriented solutions are not enough for longer-duration predictions of pedestrians&#x27; movements and thus are not ideal for motion planning and cannot support vehicle-pedestrian communications. Many research efforts have been put into recognizing pedestrians&#x27; behaviors and predicting their trajectories in the past few years. Compared with detection and tracking, the prediction of pedestrians&#x27; behaviors is way further from mature and needs more progress to support fully autonomous driving systems. <br/><br/>This Workshop will be the first one focusing on the detection, recognition, and prediction of pedestrian behaviors. The goal is to build a platform for sharing state-of-the-art models, algorithms, and datasets in the field and identifying research needs and directions.</p></div></div><div class="section-4 wf-section"><h1 id="topics" class="topics">Topics</h1><div class="container-2 w-container"></div><div class="container-4 w-container"><ul role="list" class="list-8"><li class="list-item-12">Pedestrian detection and tracking</li><li class="list-item-13">Pedestrian trajectory prediction</li><li class="list-item-14">Pedestrian intention estimation</li><li class="list-item-14">Pedestrian behavior and action recognition</li><li class="list-item-14">Factors affecting pedestrian behavior and decision-making</li><li class="list-item-14">Vehicle-pedestrian interaction</li><li class="list-item-14">Vehicle decision-making</li></ul></div></div><section id="feature-section" class="feature-section wf-section"><h1 id="Speakers" class="heading-11">Speakers</h1><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1.jpg" sizes="(max-width: 479px) 91vw, (max-width: 767px) 95vw, (max-width: 991px) 155.15625px, 245.9375px" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1-p-500.jpeg 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1-p-800.jpeg 800w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137ae8a4f880cd250bb50b0_thumbnail_jdomeyer1.jpg 914w" alt="" class="feature-image"/></div><div><h2 class="heading-9">Josh Domeyer</h2><h5>Toyota Motor North America</h5><a href="https://scholar.google.com/citations?hl=en&amp;user=z3zEcpUAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Website</a><h5>Talk title: Perceptual control guides driver-pedestrian crosswalk negotiation</h5><p class="paragraph-4"><strong>Abstract: </strong>Predicting pedestrian crossing intent can be difficult due to complex behaviors that are often interpreted differently depending on the context. Additionally, driver and pedestrian behaviors are dynamic and evolve over the encounter to produce safety, efficiency, and fairness outcomes. While machine learning techniques can sometimes predict pedestrian behaviors well, they fall short in helping to understand the mechanisms that guide pedestrian behavior. A deeper understanding of pedestrian behaviors can inform the features that are used to predict pedestrian intent. This talk will show how mechanistic models can reveal new information about pedestrian behavior. Perceptual models are implemented as differential equations and simulated to reproduce observed pedestrian and driver behaviors from naturalistic driving videos. Future directions and potential applications are discussed.</p><p class="paragraph-7"><strong>Short bio: </strong>Josh Domeyer is a senior researcher in the Toyota Collaborative Safety Research Center. He received a Ph.D. in Industrial and Systems Engineering at the University of Wisconsin-Madison in 2021 and B.S. and M.S. degrees in Experimental Psychology from Central Michigan University in 2009 and 2011. He has been a human factors researcher at Toyota since 2011 where his research has focused on driver-vehicle interface, distraction, and human-automation interaction. He joined the Collaborative Safety Research Center in 2017 to explore the communication between drivers and pedestrians with the goal of informing the development of vehicle automation. He is the Chair of SAE’s Safety and Human Factors Steering Committee and a U.S. expert for the ISO TC22/SC39/WG8 standards group.</p></div></div><div class="w-container"><div style="padding-top:56.17021276595745%" class="w-embed-youtubevideo youtube"><iframe src="https://www.youtube.com/embed/498bfmS2HSE?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b713369cc2748231c6fe4_Screen%20Shot%202021-09-10%20at%209.51.49%20AM.png" sizes="(max-width: 479px) 91vw, (max-width: 767px) 95vw, (max-width: 991px) 155.15625px, 245.9375px" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b713369cc2748231c6fe4_Screen%20Shot%202021-09-10%20at%209.51.49%20AM-p-500.png 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b713369cc2748231c6fe4_Screen%20Shot%202021-09-10%20at%209.51.49%20AM.png 738w" alt="" class="feature-image"/></div><div><h2 class="heading-9">Ali Karimoddini</h2><h5>North Carolina A&amp;T State University</h5><a href="http://akarimod.info">Website</a><h5 class="heading-10">Talk title: Robust and Computationally Effective Pedestrian Detection for Autonomous Cars</h5><p class="paragraph-4"><strong>Abstract: </strong>Real-time accurate pedestrian detection and tracking are crucial to ensure safety and reliability in autonomous driving. This often requires the estimation of multiple pedestrian trajectories from multi-modal sensor data. There are, however, several challenges that make pedestrian detection and tracking a notoriously hard task. For instance, pedestrians may appear in a scene with different articulations of body parts, partial occlusion, and appearance in various poses. Furthermore, the detection and tracking may fail due to the sensitivity of some sensors under low illumination or bright sunlight conditions.Despite all these challenges, it is vitally important for autonomous driving to achieve accurate and robust pedestrian detection and tracking under various conditions in real-time to be able to transition from the innovation space to real-world operations. In this talk, we will review our recent results on robust and efficient techniques for pedestrian detection. In particular, we present our developed techniques for fusing the information from different sensors and networks to enhance the accuracy of pedestrian detection, while managing the computation costs. We also present the results of the extensive evaluation of the developed methods in terms of runtime- efficiency and robustness of the proposed methods both on public datasets and our autonomous driving dataset. Results show our fusion method significantly improves detection rate while achieving competitive runtime efficiency.</p><p class="paragraph-6"><strong>Short bio: </strong>Ali Karimoddini is the Director of NCCAV Center of Excellence on Advanced Transportation Technology, the Deputy Director of the TECHLAV Center of Excellence in Autonomy, and the Director of the ACCESS Laboratory. His research interests include development of solutions for “Testing, evaluation, analysis, control, and decision-making for autonomous vehicles,”“Cyber-physical systems,” “Cooperative and distributed control of multi-agent systems,” “Reliable and fault tolerant control systems,” and “Human-machine interactions” with focus on their application in smart transportation systems, battlefield management, and smart agriculture domains.</p></div></div><div class="w-container"><div id="Robust-and-Computationally-Effective-Pedestrian-Detection-for-Autonomous-Cars-Speaker" style="padding-top:56.17021276595745%" class="w-embed-youtubevideo w-node-_7808ba43-35a5-3b55-77d0-bfff5bdb3907-ef9f1329"><iframe src="https://www.youtube.com/embed/BRZFOETOELA?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b70d44d7c30bcccc7f1ae_Screen%20Shot%202021-09-10%20at%209.50.33%20AM.png" sizes="(max-width: 479px) 91vw, (max-width: 767px) 95vw, (max-width: 991px) 155.15625px, 245.9375px" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b70d44d7c30bcccc7f1ae_Screen%20Shot%202021-09-10%20at%209.50.33%20AM-p-500.png 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/613b70d44d7c30bcccc7f1ae_Screen%20Shot%202021-09-10%20at%209.50.33%20AM.png 732w" alt="" class="feature-image"/></div><div><h2 class="heading-9">Amir Rasouli</h2><h5>Huawei Technologies Canada</h5><a href="https://aras62.github.io/">Website</a><h5 id="Predicting-Pedestrian-Behavior-Premise-Progress-and-Prospects-Presentation">Talk title: Predicting Pedestrian Behavior: Premise, Progress, and Prospects</h5><p class="paragraph-4"><strong>Abstract: </strong>Humans commonly rely on predicting each other’s behaviors to accomplish their goals. The driving task is no exception, which also applies to autonomous vehicles (AVs). To be safer, AVs require robust prediction systems that can accurately forecast behaviors of other road users, in particular, pedestrians as the most vulnerable ones.<br/>In this presentation, I will provide an overview of pedestrian behavior prediction in the context of autonomous driving. I will begin by discussing the motivation behind developing predictive models, followed by a summary of psychological studies of pedestrians and factors that impact their behavior. I will continue by describing the current progress in the field and will talk about existing driving datasets for research and development and state-of-the-art pedestrian behavior prediction models. I will conclude the presentation by enumerating some of the open problems in the field.</p><p class="paragraph-8"><strong>Short bio: </strong>Amir Rasouli is a senior research scientist leading pedestrian prediction team at Noah’s Ark Laboratory, Huawei, Canada. He received B.Eng. degree in computer systems engineering and B.A. in Business Management from the Royal Melbourne Institute of Technology. He obtained M.A.Sc. degree in computer engineering under the supervision of Prof. John Tsotsos at York University studying the role of attention in active visual object search for mobile robots. He completed his Ph.D. degree in the same lab on the topic of pedestrian behavior understanding and prediction in the context of autonomous driving. His current work focuses on various aspects of pedestrian behavior prediction including analysis of naturalistic driving data, understanding theoretical foundations of pedestrian-driver interaction, modeling pedestrian behavior in simulation, and development of predictive models for intelligent driving systems.</p></div></div><div class="w-container"><div style="padding-top:56.17021276595745%" class="w-embed-youtubevideo"><iframe src="https://www.youtube.com/embed/vzwfhd_nobI?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613f81a194b9fddf0977eea2_download.png" sizes="(max-width: 479px) 91vw, (max-width: 767px) 95vw, (max-width: 991px) 155.15625px, 245.9375px" srcset="https://uploads-ssl.webflow.com/613787b27794b085129f1328/613f81a194b9fddf0977eea2_download-p-500.png 500w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/613f81a194b9fddf0977eea2_download-p-800.png 800w, https://uploads-ssl.webflow.com/613787b27794b085129f1328/613f81a194b9fddf0977eea2_download.png 853w" alt="" class="feature-image"/></div><div><h2 class="heading-9">Tina Chen</h2><h5>Indiana University Purdue University Indianapolis</h5><a href="http://www.linkedin.com/in/tinachen92">Website</a><h5 class="heading-12">Talk title: Pedestrian Intention Prediction using Environmental Context</h5><p class="paragraph-4"><strong>Abstract: </strong>For autonomous vehicles and pedestrians to co-exist on the road as seamlessly as possible, autonomous vehicles should have the capability to navigate with pedestrian intention and motivation in mind rather than just react to pedestrian actions that are already in progress. Predicting human behavior can be a highly difficult task due to the many variables that can affect our behavior, but through computer vision techniques and the usage of neural networks, we can include more and more context in our predictive models. In this presentation, I will focus on research in predicting pedestrian crossing intention from the ego-view which mainly uses computer vision and deep learning. I will start with an overview of the state-of-the-art prediction models in the autonomous vehicle field. Then I will introduce a predictive model that I am working on that factors in environment and pedestrian visual features for prediction. Many of the important context cues that factor into a pedestrian’s intention are missing from predictive models, and my model will show context improves intention prediction. The presentation will be concluded with future research directions.</p><p class="paragraph-9"><strong>Short bio: </strong>Tina Chen recently graduated with an M.S. in Computer Engineering from Indiana University <br/>Purdue University - Indianapolis. She received her B.S. in Electrical Engineering from the University of Wisconsin - Madison in 2015. She has more than 5 years of experience working on, researching, and evaluating sensing systems and algorithms for advanced driver assistance and automated driving systems. Her current work mainly focuses on using machine learning and computer vision to improve pedestrian behavior prediction for autonomous vehicle applications. She is working on a deep learning algorithm that uses both visual features and object spatial relationships to predict pedestrian crossing behavior. Additionally, she is also developing a dataset focused on understanding pedestrian behavior through driving decisions.</p></div></div><div class="container-5 w-container"><div id="Pedestrian-Intention-Prediction-using-Environmental-Context" style="padding-top:56.17021276595745%" class="w-embed-youtubevideo w-node-_6df24056-f247-72cc-88a6-b75581413876-ef9f1329"><iframe src="https://www.youtube.com/embed/gDO9wJLCsE4?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div><div class="flex-container w-container"><div class="feature-image-mask"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137a8e766e8e4223e9a0d62_Screen%20Shot%202021-09-06%20at%2010.32.55%20PM.png" alt="" class="feature-image"/></div><div><h2>Renran Tian</h2><h5>Indiana University Purdue University Indianapolis</h5><a href="https://et.iupui.edu/people/rtian">Website</a><h5>Talk title: Situated Pedestrian Intent from the Driver’s Perspective: Theory and Challenge</h5><p class="paragraph-10"><strong>Abstract: </strong>With the progress of automated driving technology going into the city streets, pedestrian behavior has drawn a lot of attention. Most of the continued efforts in developing benchmark datasets and prediction algorithms focus on pedestrian trajectories and activities. However, one question is whether pedestrian trajectory and activity are entirely predictable or not, or what shall be the expected performance level. In this talk, I will describe the view of situated pedestrian intent from the driver’s perspective to depict the dynamics of pedestrian behavior during driver-pedestrian encounters. Some empirical results show the differences among human drivers in understanding pedestrian intents, highlighting the difficulties in accurately predicting their behaviors and advocating the importance of designing vehicle control strategies considering the nondeterministic characteristics of the encountering process.</p><p class="paragraph-11"><strong>Short bio: </strong>Dr. Renran Tian is an assistant professor in the Department of Computer Information &amp; Graphics Technology and the Transportation &amp; Autonomous Systems Institute (TASI) at Indiana University-Purdue University Indianapolis (IUPUI). He received his Ph.D. degree from the School of Industrial Engineering at Purdue University –West Lafayette in 2013, and B.S. and M.S. in Mechanical <br/>Engineering from Tsinghua University – Beijing, China in 2002 and 2005. His research interests include human-centered computing, cognitive ergonomic, computational behavior analysis, human-AI interaction, and autonomous driving. He serves as the co-chair for Technical Activities Committee on Human Factors in Intelligent Transportation Systems (HFITS), IEEE Intelligent Transportation Systems Society.</p></div></div><div class="w-container"><div id="Situated-Pedestrian-Intent-from-the-Driver-s-Perspective-Theory-and-Challenge" style="padding-top:56.17021276595745%" class="w-embed-youtubevideo youtube-2 w-node-_1594a4d7-4912-7a3d-7ac9-a697060aa084-ef9f1329"><iframe src="https://www.youtube.com/embed/7GhvR1DfsG0?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div></div></section><footer id="footer" class="footer wf-section"><div class="w-container"><div class="footer-flex-container"><div class="text-block-2">For information, please contact <a href="mailto:rtian@iupui.edu" target="_blank">rtian@iupui.edu</a>.<br/></div><a href="#" class="footer-logo-link"><img src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/6137a4b216a9ecb99f874d0c_Screen%20Shot%202021-09-07%20at%2012.42.50%20PM.png" alt="" class="footer-image"/></a></div></div></footer><script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=613787b27794b085129f1328" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script><script src="https://uploads-ssl.webflow.com/613787b27794b085129f1328/js/webflow.36c130058.js" type="text/javascript"></script><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]--></body></html>
